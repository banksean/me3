[
	{
		"filename": "blaim/vscode-extension/playground.js",
		"position": {
			"line": 21,
			"character": 33
		},
		"text": "um(a, b",
		"inference_config": {
			"endpoint": "",
			"maxLines": 0,
			"maxTokens": 5,
			"temperature": 0.2,
			"modelName": "codellama",
			"modelFormat": "",
			"delay": 0
		}
	},
	{
		"filename": "blaim/vscode-extension/playground.js",
		"position": {
			"line": 21,
			"character": 40
		},
		"text": ") {\n  return",
		"inference_config": {
			"endpoint": "",
			"maxLines": 0,
			"maxTokens": 5,
			"temperature": 0.2,
			"modelName": "codellama",
			"modelFormat": "",
			"delay": 0
		}
	},
	{
		"filename": "blaim/vscode-extension/playground.js",
		"position": {
			"line": 22,
			"character": 52
		},
		"text": " a + b;\n",
		"inference_config": {
			"endpoint": "",
			"maxLines": 0,
			"maxTokens": 5,
			"temperature": 0.2,
			"modelName": "codellama",
			"modelFormat": "",
			"delay": 0
		}
	},
	{
		"filename": "blaim/vscode-extension/playground.js",
		"position": {
			"line": 23,
			"character": 60
		},
		"text": "}\n\n// This",
		"inference_config": {
			"endpoint": "",
			"maxLines": 0,
			"maxTokens": 5,
			"temperature": 0.2,
			"modelName": "codellama",
			"modelFormat": "",
			"delay": 0
		}
	},
	{
		"filename": "blaim/vscode-extension/playground.js",
		"position": {
			"line": 26,
			"character": 95
		},
		"text": "function testSum() {",
		"inference_config": {
			"endpoint": "",
			"maxLines": 0,
			"maxTokens": 5,
			"temperature": 0.2,
			"modelName": "codellama",
			"modelFormat": "",
			"delay": 0
		}
	},
	{
		"filename": "blaim/vscode-extension/playground.js",
		"position": {
			"line": 27,
			"character": 118
		},
		"text": "let v = sum(",
		"inference_config": {
			"endpoint": "",
			"maxLines": 0,
			"maxTokens": 5,
			"temperature": 0.2,
			"modelName": "codellama",
			"modelFormat": "",
			"delay": 0
		}
	},
	{
		"filename": "blaim/vscode-extension/playground.js",
		"position": {
			"line": 27,
			"character": 130
		},
		"text": "2, 3);",
		"inference_config": {
			"endpoint": "",
			"maxLines": 0,
			"maxTokens": 5,
			"temperature": 0.2,
			"modelName": "codellama",
			"modelFormat": "",
			"delay": 0
		}
	},
	{
		"filename": "blaim/vscode-extension/playground.js",
		"position": {
			"line": 18,
			"character": 2
		},
		"text": "//console.log(",
		"inference_config": {
			"endpoint": "",
			"maxLines": 0,
			"maxTokens": 5,
			"temperature": 0.2,
			"modelName": "codellama",
			"modelFormat": "",
			"delay": 0
		}
	},
	{
		"filename": "blaim/vscode-extension/playground.js",
		"position": {
			"line": 18,
			"character": 15
		},
		"text": "(v);\n}",
		"inference_config": {
			"endpoint": "",
			"maxLines": 0,
			"maxTokens": 5,
			"temperature": 0.2,
			"modelName": "codellama",
			"modelFormat": "",
			"delay": 0
		}
	},
	{
		"filename": "blaim/vscode-extension/playground.js",
		"position": {
			"line": 23,
			"character": 61
		},
		"text": "\n\n// This is",
		"inference_config": {
			"endpoint": "",
			"maxLines": 0,
			"maxTokens": 5,
			"temperature": 0.2,
			"modelName": "codellama",
			"modelFormat": "",
			"delay": 0
		}
	},
	{
		"filename": "blaim/vscode-extension/playground.js",
		"position": {
			"line": 33,
			"character": 236
		},
		"text": "\nfunction testDemo()",
		"inference_config": {
			"endpoint": "",
			"maxLines": 0,
			"maxTokens": 5,
			"temperature": 0.2,
			"modelName": "codellama",
			"modelFormat": "",
			"delay": 0
		}
	},
	{
		"filename": "blaim/vscode-extension/playground.js",
		"position": {
			"line": 26,
			"character": 113
		},
		"text": " {\n  let v",
		"inference_config": {
			"endpoint": "",
			"maxLines": 0,
			"maxTokens": 5,
			"temperature": 0.2,
			"modelName": "codellama",
			"modelFormat": "",
			"delay": 0
		}
	},
	{
		"filename": "blaim/vscode-extension/playground.js",
		"position": {
			"line": 35,
			"character": 266
		},
		"text": " = demoVar + demo",
		"inference_config": {
			"endpoint": "",
			"maxLines": 0,
			"maxTokens": 5,
			"temperature": 0.2,
			"modelName": "codellama",
			"modelFormat": "",
			"delay": 0
		}
	},
	{
		"filename": "blaim/vscode-extension/playground.js",
		"position": {
			"line": 35,
			"character": 283
		},
		"text": "2;\n  //",
		"inference_config": {
			"endpoint": "",
			"maxLines": 0,
			"maxTokens": 5,
			"temperature": 0.2,
			"modelName": "codellama",
			"modelFormat": "",
			"delay": 0
		}
	},
	{
		"filename": "blaim/vscode-extension/playground.js",
		"position": {
			"line": 18,
			"character": 4
		},
		"text": "console.log(v",
		"inference_config": {
			"endpoint": "",
			"maxLines": 0,
			"maxTokens": 5,
			"temperature": 0.2,
			"modelName": "codellama",
			"modelFormat": "",
			"delay": 0
		}
	},
	{
		"filename": "blaim/vscode-extension/playground.js",
		"position": {
			"line": 18,
			"character": 17
		},
		"text": ");\n}\n\n",
		"inference_config": {
			"endpoint": "",
			"maxLines": 0,
			"maxTokens": 5,
			"temperature": 0.2,
			"modelName": "codellama",
			"modelFormat": "",
			"delay": 0
		}
	}
]
